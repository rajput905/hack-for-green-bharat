"""
GreenFlow AI - AI Query Route

Accepts natural-language environmental questions and returns
RAG-powered answers generated by OpenAI.
"""

from __future__ import annotations

from typing import Annotated

from fastapi import APIRouter, Depends
from sqlalchemy.ext.asyncio import AsyncSession

from app.database.session import get_db
from app.schemas import QueryRequest, QueryResponse
from app.services.analytics import analytics_service
from app.services.chatbot import chatbot_service

router = APIRouter(prefix="/query", tags=["AI Query"])

DbDep = Annotated[AsyncSession, Depends(get_db)]


@router.post(
    "",
    response_model=QueryResponse,
    summary="Ask an environmental question to GreenFlow AI",
)
async def query_ai(request: QueryRequest, db: DbDep) -> QueryResponse:
    """
    Submit a natural-language question to the RAG engine.

    The system automatically enriches the prompt with the latest
    live CO2 reading from the database before querying OpenAI.

    Args:
        request: Validated query request containing the question.
        db:      Injected async database session.

    Returns:
        AI-generated answer with source references and latency.
    """
    # Inject live CO2 context from the most recent event
    latest = await analytics_service.get_latest_event(db)
    live_co2 = latest.co2_ppm if latest else None

    result = await chatbot_service.get_answer(
        query=request.query,
        db=db,
        live_co2=live_co2,
    )

    return QueryResponse(
        answer=result["answer"],
        sources=result.get("sources", []),
        latency_ms=result.get("latency_ms", 0.0),
    )
